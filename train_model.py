import  pandas as pdimport torchimport torch.nn as nnimport torch.nn.functional as F  from torch.utils.data import Dataset, DataLoader   from torchsummary import summaryfrom torchvision import transforms  import os import  cv2import  numpy as npfrom glob import  globimport segmentation_models_pytorch as smpfrom segmentation_models_pytorch import utilsfrom sklearn.model_selection import train_test_splitfrom torchsummary import summarynum_epochs=40CLASSES = 21dataset=glob("./dataset/images/*.png")dataset=pd.DataFrame(dataset,columns=["image"])dataset["mask"]=dataset["image"].apply(lambda x : "./dataset/masks/"+x.rsplit("/")[-1])dataset=dataset.sample(frac=1,ignore_index=True)train_dataset,val_dataset=train_test_split(dataset,test_size=.2)class costum_dataset(Dataset):    def __init__(self,dataset, transform=None, target_transform=None):        super().__init__()        self.dataset=dataset        self.transform=transform        self.target_transform=target_transform            def __len__(self):        return(len(self.dataset))        def __getitem__(self, index) :        img,msk=self.dataset.iloc[index][["image","mask"]]        image=cv2.imread(img)        mask=cv2.imread(msk, cv2.IMREAD_GRAYSCALE)                        if self.transform :            image=self.transform(image)                    if self.target_transform :            mask=self.target_transform(mask)                return (image.float(),mask.float())    def target_transform (mask):    mask=F.one_hot(torch.tensor(mask).long(),CLASSES)    mask=torch.permute(mask,(2,0,1))    return(mask)transform=transforms.Compose([transforms.ToTensor()])train_set=costum_dataset(train_dataset ,transform=transform ,target_transform=target_transform)val_set=costum_dataset(val_dataset ,transform=transform  ,target_transform=target_transform)train_loader=DataLoader(train_set,batch_size=16)valid_loader=DataLoader(val_set,batch_size=16)steps=len(train_loader)ENCODER = 'resnext50_32x4d'ENCODER_WEIGHTS = 'imagenet'ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multiclass segmentation# create segmentation model with pretrained encoder model = smp.PSPNet(     encoder_name=ENCODER,     encoder_weights=ENCODER_WEIGHTS,     in_channels=3,     classes=CLASSES,     activation=ACTIVATION, )model=torch.load("./model.pt",map_location=torch.device('cpu'))print(summary(model,(3,504,504)))# preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)TRAINING = True# Set device: `cuda` or `cpu`# DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")# define loss functioncriterion = utils.losses.DiceLoss()metrics = [utils.metrics.IoU(threshold=0.5),utils.metrics.Accuracy()]# define optimizeroptimizer = torch.optim.Adam([dict(params=model.parameters(), lr=0.0001),])lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(    optimizer, T_0=1, T_mult=2, eta_min=5e-5,)train_epoch = utils.train.TrainEpoch(    model,     loss=criterion,     metrics=metrics,     optimizer=optimizer,    # device=DEVICE,    verbose=True,)valid_epoch = utils.train.ValidEpoch(    model,     loss=criterion,     metrics=metrics,     # device=DEVICE,    verbose=True,)best_iou_score = 0.0train_logs_list, valid_logs_list = [], []for i in range(0, num_epochs):    # Perform training & validation    print('\nEpoch: {}'.format(i))    train_logs = train_epoch.run(train_loader)    valid_logs = valid_epoch.run(valid_loader)    train_logs_list.append(train_logs)    valid_logs_list.append(valid_logs)    torch.save(model,f"./checkpoint/model_{i}.pt") total_step=len(train_loader) for epoch in range(1,num_epochs+1):     for step,(imgs,msks) in enumerate(train_loader):         pred=model(imgs)         f_pred=torch.squeeze(torch.argmax(pred, dim=1, keepdim=True))         f_msks=torch.squeeze(torch.argmax(msks, dim=1, keepdim=True))         acc=100*torch.sum(f_pred==f_msks)/(504*504*16)         loss=criterion(msks,pred)         optimizer.zero_grad()         loss.backward()         optimizer.step()         print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}% '                         .format(epoch, num_epochs, step+1, total_step, loss.item(), acc.item()))             